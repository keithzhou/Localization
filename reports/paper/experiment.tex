\chapter{Experiment}
In this chapter, we first discuss the hardware equipments that are used to build the final system. Next we discuss the high level software architecture we designed and implemented in our system. We then detail the localization method we used in our system and how we circumvented the need to synchronize clocks across the two arrays. We then describe the experiments we have conducted using our system to test its localization accuracy and system responsiveness. These experiments include acoustic source location estimates and movement tracking. In the discussion section of this chapter we analyze the results from the experiments above. To conclude this chapter, we have included several interesting applications of our system demonstrating how it can be used to facilitate human computer interaction. 


\section{System}
\input{./system}
\clearpage

\section{Setup}

We conducted two sets of experiments to evaluate the system's localization accuracy: one on point localization and the other on movement tracking. For the point localization experiment we looked into using different window size of audio signals and different prefiltering methods. The size of the window limits how far apart the microphone arrays can be. If the time delay from one microphone array to another exceeds the size of the window, the location of the source can never be estimated. A large window size gives a more complete acoustic signal which makes cross-correlation less prone to noise. However, the larger the window size the more time it takes to compute the cross-correlation. This is a trade off that we will address.  

For the movement tracking experiment, on top of the varying window size, we also looked into varying the movement speed of the audio source, applying different movement filters, and using different types of audio source. By applying an increasing movement speed of the audio source, we can test how fast the system can track an audible object moving in real time. We experimented with two types of music as our audio source for movement tracking, one with no low volume throughout, and the other with intermittent low or no volume. We want to test how the system performs when the audio source isn't continuously outputting sound. Furthermore, we applied different movement filters to help reduce noise and smooth out the path of the moving audio source.  

\subsection{Point localization}

\begin{figure}[h!]
  \centering
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{setup_1.JPG}
    \caption{1 meter by 1 meter grid}
  \end{subfigure}
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{setup_2.JPG}
    \caption{array placement}
  \end{subfigure}
  \caption{Setup for point localization evaluation}
  \label{fig:setup_point}
\end{figure}

An one meter by one meter grid was set up where the arrays were placed at the top left and top right corners of the grid. Fig~\ref{fig:setup_point} shows a picture of the setup. A total of $32$ testing locations were chosen uniformly in this grid. Testing is done by placing the audio source at each grid location, and turning on the audio source with white noise. We reported the error as the average distance between our placement of the audio source and the location estimated from the arrays.

\subsection{Movement tracking}

\begin{figure}[h!]
  \centering
%  \begin{subfigure}[]{.2\textwidth}
%    \includegraphics[width=\textwidth]{setup_ring.JPG}
%  \end{subfigure}
  \begin{subfigure}[]{1.0\textwidth}
    \includegraphics[width=\textwidth]{setup_rotating_disk.JPG}
  \end{subfigure}
  \caption{Setup for movement tracking evaluation}
  \label{fig:setup_circle}
\end{figure}


To test how well the system tracks movement, we mounted a rotating disk $40$ centimeters in diameter onto the grid at $(x=0$ cm$, y=-30$ cm$)$. Fig~\ref{fig:setup_circle} shows a picture of the setup. A sound source is placed on the edge of the rotating disk and the arrays track the sound source as it rotates in a circle. In this experiment we used GCC\_PHAT as the prefiltering for cross-correlation because in the point localization experiment we found out GCC\_PHAT gives the best result. In this experiment, we evaluated how accuracy changes with:
\begin{itemize}
\item window sizes 
\item audio sources
\item movement tracking filters
\item movement speeds
\end{itemize}

To test how localization accuracy varies with different window size of audio signal received, we conducted the experiment with audio signals with varying length from 1.02 ms to 12 ms.

To test how different sound sources impact localization quality, we conducted the experiments with three different sound sources:
\begin{description}%[\IEEEsetlabelwidth{long a label}\IEEEusemathlabelsep]

\item[White Noise] A recording of white noise. We expect GCC\_PHAT works best with white noise. The white noise is generated by sampling uniform randomly between $-1$ and $1$.

\item[Music A] A randomly picked music that has non-zero audio amplitude throughout the experiment period. \emph{Honest Eyes} by \emph{Black Tide} was the music used.

\item[Music B] A randomly picked music with intermittent low amplitude sections. \emph{Canon} was the music used.

\end{description} 

To test how the movement speed of sound source affects localization quality, each experiment was conducted at two different speeds:

\begin{description}
\item[Normal] An angular speed of $0.5$ rad/s was maintained, which translates to a linear speed of $10$ cm/s.
\item[Fast] An angular speed of $1.0$ rad/s was maintained, which translates to a linear speed of $20$ cm/s.
\end{description}

For each experiment conducted, two different movement filters were evaluated:
\begin{description}%[\IEEEsetlabelwidth{Very long label}\IEEEusemathlabelsep]
\item[Averaging filter] localization for past $0.5$ seconds were averaged and outputted as current estimate.
\item[Kalman filter] A 2nd order Kalman filter was used.
\end{description}

In the movement tracking experiments described above, we know the ground truth location of the circle, but not the exact location of the audio source at each moment during the movement. Therefore, the error is reported as the distance between the localized point to its closest point on the ground truth circle.
\clearpage

\section{Results}
\subsection{Point localization}
\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{average_error_window_size.eps}
\caption{Localization error versus window size}
\label{fig:accuracy_vs_window}
\end{figure}
To test how accuracy varies with window size, the algorithm is fed with microphone data of different lengths, and the result is shown in fig~\ref{fig:accuracy_vs_window}. The error decreases as window size increases and plateaus after the window size exceeds around $10$ millisecond. The lowest error achieved is $2.53$ centimeters, which occurred when the window size is set to 12 millisecond and when GCC\_PHAT is used for TDOA estimation. The performance differences among GCC, GCC\_PHAT and GCC\_PHAT\_SQRT is small.

\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{calculation_time.eps}
\caption{Computation time versus window size}
\label{fig:speed_vs_window}
\end{figure}
As was mentioned before, although accuracy improves with the window size, computation time also increases with it. The part of calculation that depends on the window size is using cross correlation for TDOA estimation. Cross correlation can be calculated with Fast Fourier Transform (FFT) and the runtime is of order $O(N\log N)$. We measured how the computation time varied with window size and Figure~\ref{fig:speed_vs_window} shows the result. The runtime increases approximately linearly in the window size region of interest.

\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{error_distribution.eps}
\caption{Error distribution in the grid. Arrays are placed at $(-0.5$ m$, 0$ m$)$ and $(0.5$ m$, 0$ m$)$}
\label{fig:error_distribution}
\end{figure}
We also calculated the localization error for each tested point in the grid. Figure~\ref{fig:error_distribution} shows the error distribution inside the grid. The error is below $3$ cm for most areas inside the grid. However, note that there is one error spike in the mid-left region in the grid. We attribute this inconsistency with the surrounding region to errors we have made in placing the audio source, since manually placing the audio source with centimeter precision is difficult. To confirm this speculation, we later reevaluated the errors in this region and found them to be close to the errors in the surrounding region. 

\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{error_along_y_axis.eps}
\caption{Localization error as the distance between the source and the microphone arrays increases. The source is placed on the $y$ axis.}
\label{fig:error_along_y}
\end{figure}
To test the limit of the system and to evaluate the accuracy when the source moves outside of the one meter by one meter region, we measured the localization error by placing the source at $10$ locations along $y$ axis ranging from $(0$ cm$, -10$ cm$)$ to $(0$ cm$, -200$ cm$)$. The result is presented in fig~\ref{fig:error_along_y}. The localization error is on average below $3$ cm when the source is within $100$ cm along the $y$ axis from the arrays. The error increases to about $5$ cm when the source distance increases to $150$ cm and the error exceeds $10$ cm after the source distance reaches $200$ cm. We can see that our system achieves good accuracy within the one meter by one meter region and gradually loses its localization accuracy as we move the source outside.  

%\clearpage
\subsection{Movement tracking}
\begin{figure*}[h!]
\centering
  \includegraphics[width=\textwidth]{trace_window_size_movement.eps}
\caption{Localization quality versus window size}\label{fig:wn}
\label{fig:trace_win_circle}
\end{figure*}

\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{error_window_size_movement.eps}
\caption{Localization error versus window size}
\label{fig:err_win_circle}
\end{figure}
Fig~\ref{fig:wn} gives an intuitive representation of how accuracy changes with window size. When window size is small ($1.02$ millisecond), the audio does not contain enough information to reliably estimate TDOA, which results in noisy localization. As window size increases, the TDOA estimation becomes more accurate and the localization converges to the shape of the ground truth circle. Fig~\ref{fig:err_win_circle} shows how the error changes with window size. The general trend is similar to that in point localization case. Error decreases as the window size increases and plateaus after it exceeds around $10$ milliseconds.

\begin{figure*}[h!]
\centering
\includegraphics[width=1.0\textwidth]{trace_output_circle_wnn.eps}
\caption{white noise ($10$ cm per second)}
\label{fig:circle_wnn}
\end{figure*}

Fig~\ref{fig:circle_wnn} shows the result when white noise is used as the sound source and the source is rotated at $10$ cm per second. The top right plot in this figures shows the raw detection output with the ground truth circle overlayed on top. It shows that the array's raw output matches the underneath ground truth circle reasonably well. The average error between the localization output with its closest point on the ground truth circle is $0.9$ cm. The top left plot in the figure shows the average error with different movement filters applied as a function of window size. The error decreases as window size increases until the window size exceeds around $10$ ms. When the window size is $12$ cm, the localization accuracy is similar among raw output, Kalman filtering output and averaging filtering output. The bottom left plot shows the tracked movement for averaging filter and the bottom right filter shows the tracked movement for Kalman filtering. Kalman filtering result is smoother while the averaging tracking stays closer to the ground truth circle. Compared to the experiment in fig~\ref{fig:circle_wnf}, where the same sound source is played but rotated at a faster linear speed of $20$ cm per second, we find that the performance is equally good between these two movement speeds.

\begin{figure*}[h!]
\centering
\includegraphics[width=1.0\textwidth]{trace_output_circle_man.eps}
\caption{music A ($10$ cm per second)}
\label{fig:circle_musican}
\end{figure*}

Fig~\ref{fig:circle_musican} shows the result when Music A is used as the sound source.  The top right plot shows that the array still tracks the movement well, but has a slightly larger deviation compared to that in fig~\ref{fig:circle_wnn} when white noise was used. The average localization error for Music A is $1.289$ cm. From the top left plot, it can be seen that the error still decreases with the window size. The performance improvement from raw output to Kalman filtering output is bigger than that with white noise (top left plot of fig~\ref{fig:circle_wnn}). Averaging filtering still produces lowest average error. Fig~\ref{fig:circle_musicaf} shows the result for the same sound source moved at twice the speed ($20$ cm per second). The average localization error at the faster speed is $1.291$ cm. Comparing the two experiments where music A was used as the sound source but with different movement speed, we find that the performance does not degrade as the movement speed increases from $10$ cm per second to $20$ cm per second. 

\begin{figure*}[h!]
\centering
\includegraphics[width=1.0\textwidth]{trace_output_circle_mbn.eps}
\caption{music B ($10$ cm per second)}
\label{fig:circle_musicbn}
\end{figure*}

Fig~\ref{fig:circle_musicbn} shows the result when Music B is used as the sound source.  The low amplitude intervals in Music B affects the performance significantly. The average localization error is $2.9$ cm. The ``blank'' regions in the music can also be visually seen from the top right plot. The top left plot shows that the Kalman filtering still performs better than raw output. The performance improvement of Kalman filtering is similar to that with Music A. Averaging filtering produces lowest average error. Comparing to the faster movement experiment of the same sound source (shown in fig~\ref{fig:circle_musicbf}), we find that the localization error is similar between these two movement speeds.

\begin{figure*}[h!]
\centering
\includegraphics[width=1.0\textwidth]{trace_output_circle_wnf.eps}
\caption{white noise ($20$ cm per second)}
\label{fig:circle_wnf}
\end{figure*}

\begin{figure*}[h!]
\centering
  \includegraphics[width=1.0\textwidth]{trace_output_circle_maf.eps}
  \caption{music A ($20$ cm per second)}
  \label{fig:circle_musicaf}
\end{figure*}

\begin{figure*}[h!]
\centering
  \includegraphics[width=1.0\textwidth]{trace_output_circle_mbf.eps}
  \caption{music B ($20$ cm per second)}
  \label{fig:circle_musicbf}
\end{figure*}

\subsection{Discussion}

Different prefiltering options produce very similar result. GCC\_PHAT gives slightly better accuracy, but the difference among unfiltered GCC, GCC\_PHAT and GCC\_PHAT\_SQRT is very small. 

By comparing experiments at normal speed (fig~\ref{fig:circle_wnn} to \ref{fig:circle_musicbn}) with experiments at fast speed (fig~\ref{fig:circle_wnf} to~\ref{fig:circle_musicbf}), we find that the localization error does not increase when the movement speed increased from $10$ cm per second to $20$ cm per second. However, it's conceivable that the localization error will increase with further speed increase, but since our system is designed for HCI, a speed of $20$ cm per second covers most of the use cases. 

When white noise is used as the audio source, Kalman filtering and raw localization produces very similar accuracy, and averaging filter gives slightly higher accuracy. However, when the audio source is changed to Music A or Music B, Kalman filtering produces better accuracy compared to raw detection, but Averaging filter still gives the best result. Looking at the smoothness of the movement path after applying different movement filters, it can be seen that raw detection has the most amount of jiggling. Kalman filter reduces the amount of jiggling from raw detection by combining past estimates with current estimates. Averaging filter has the least amount of jiggling. However, averaging filter averages detection outputs from past $0.5$ seconds, which makes the filtered output lag the real movement.

\begin{figure}[h!]
  \centering
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{show_l.png}
    \caption{drawing letter `L'}
  \end{subfigure}
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{show_m.png}
    \caption{drawing letter `M'}
  \end{subfigure}

  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{show_r.png}
    \caption{drawing letter `R'}
  \end{subfigure}
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{show_c.png}
    \caption{drawing letter `C'}
  \end{subfigure}
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{show_n.png}
    \caption{drawing letter `N'}
  \end{subfigure}
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{show_b.png}
    \caption{drawing letter `B'}
  \end{subfigure}
  \caption{Drawing letters. Green dots represent raw localization output and the red line is the output after averaging filtering.}
  \label{fig:show_case}
\end{figure}

In figure~\ref{fig:show_case}, a few examples of drawing letters with music are presented. Each letter took around $5$ to $10$ seconds to draw, depending on the size of the letter and the speed of the movement. Green dots on the plots represent the raw localization output and the red line shows the movement output with averaging filtering (window size of $0.5$ seconds is used). The demonstrated letters are drawn with free hand, without a track guiding the movement. The accuracy is reasonably good, and each letter can be easily recognized. There is a bit of jiggling in the tracked movement. Part of the jiggling can be attributed to the noise from system output, and the rest comes from the hand movement. 

\begin{figure}[h!]
  \centering
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{scaling_pos.png}
    \caption{randomly traverse the region to collect location $(x,y)$ and received power data. The volume of the source is kept constant}
    \label{fig:color_pos}
  \end{subfigure}
  \centering
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{color_scaling.png}
    \caption{calculate a scaling factor $b_{xy}$ for each point in the region. The scaling factor is the average power of $5$ closest points from the traversed points on the left}
    \label{fig:color_scale}
  \end{subfigure}
  \caption{Volume control normalization. Two microphone arrays are placed at $(-50\mbox{ cm}, 0\mbox{ cm})$ and $(50\mbox{ cm}, 0\mbox{ cm})$.}
  \label{fig:color_norm}
\end{figure}

The volume of the acoustic source can also be used to control the color of the dots painted in the above experiment. For signal $x_i[n]$ received at each microphone $i$, the power $P_i$ can be used as an indicator of the source volume:
\[
P_i = \frac{1}{N} \sum_{i=1}^N x_i[i]^2
\]

Since there are $6$ microphones in our system ($3$ in each array), we choose the maximum power $P$ received across all $6$ microphones as the indicator for the source volume:
\[
P = \max_i P_i 
\]

However, the received power of the audio signal is itself a function of the audio source location (since the received power decays with increasing distance between the source to receiver). Therefore, the received power needs to be normalized. For the power $P$ received at location $(x,y)$, we normalize it by a scaling factor $b_{xy}$. The normalized power $\bar{P}$ is:

\[
\bar{P} = \frac{P}{b_{xy}}
\]

The scaling factor $b_{xy}$ is location dependent. To calculate $b_{xy}$, we conduct an one time calibration step at the beginning. During the calibration step, a white noise sound source is used to randomly traverse the entire region with constant volume. As the source moves around in the region the calibration modules collects the source's location and the received power information. Then $b_{xy}$ can be calculated for each location $(x,y)$  by taking the average power of $5$ closest samples from that location. Fig~\ref{fig:color_norm} shows an example of the volume control calibration procedure for calibrating the location power information in a $60$ cm by $40$ cm region. Fig~\ref{fig:color_pos} shows how the white noise source with constant volume is traversed in the region and fig~\ref{fig:color_scale} shows the corresponding scaling factor $b_{xy}$ for each point in the region by taking the average power of $5$ closest points in fig~\ref{fig:color_pos}. As can be seen from the figure, for any fixed $y$ coordinate, the received power first decreases then increases along increase in the $x$ direction. This is because the arrays are placed at the top left and top right corners of the region. For a fixed $x$ coordinate, the received power decreases monotonically along the $y$ direction.

\begin{figure}[h!]
\centering
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{color_1.png}
    \caption{drawing a stripe with maximum volume}
    \label{fig:show_color_1_1}
  \end{subfigure}
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{color_2.png}
    \caption{Drawing another stripe with the volume decreased by $20\%$}
    \label{fig:show_color_1_2}
  \end{subfigure}
  \begin{subfigure}[]{.48\textwidth}
    \includegraphics[width=\textwidth]{color_3.png}
    \caption{Drawing a third stripe with the volume decreased by an additional $20\%$}
    \label{fig:show_color_1_3}
  \end{subfigure}
  \caption{Drawing stripes where the color of each stripe is controlled by the volume of the white noise}
  \label{fig:show_color}
\end{figure}


To show how the volume acts as a color control. A simple experiment is shown in Figure~\ref{fig:show_color}. In this experiment, three stripes are drawn with the same acoustic source but different volume. The color is generated in the Hue-Saturation-Value color space where the Saturation and Value are set to $0.9$ while the hue is controlled by the volume. Figure~\ref{fig:show_color_1_1} shows the first stripe where the volume is set to the maximum and the painted color is in the red to orange range. In fig~\ref{fig:show_color_1_2}, we painted another strip after the volume is decreased by $20$ percent. The painted color changed to the blue to purple range after the volume is decreased. In fig~\ref{fig:show_color_1_3}, we painted a third strip where we further decreased the volume by another $20$ percent. In this final stripe, the color changed to the green to yellow range. A video demonstration is available at~\cite{demo:color}.

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{color_5.png}
    \caption{Painting an ellipse. The color of the painting is controlled by the volume of the white noise.}
    \label{fig:show_color_3}
\end{figure}

To test how sensitive the color change is to the different volumes in our system, we have conducted the following experiment. In this experiment, we moved the acoustic source clockwise in an elliptical fashion. As we are moving the source, we varied the source volume gradually and noted its color change. We started with the volume set to the maximum (the corresponding color is red). Then we gradually decreased the volume as the move to the right. After the volume is decreased to $60\%$ of the maximum, we started to gradually increase the volume until the maximum is reached again. Figure~\ref{fig:show_color_3} gives a visual presentation of the painted result. As can be seen from the figure, the top left region of the drawn ellipse is red. The color then gradually changes to the green yellow range and then back to the red orange range as we complete the ellipse. A video demonstration of this experiment is available at~\cite{demo:color3}.

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{color_4.png}
    \caption{Painting a heart shape with a pop music by free hand. The color of the heart changes with the volume of the song.}
    \label{fig:show_color_2}
\end{figure}

Instead of manually varying the volume of the acoustic source, a natural extension is to use music as our acoustic source. Generally, the volume of music will vary with time and this change will be reflected by the colors drawn. In figure~\ref{fig:show_color_2}, we used a pop song as our acoustic source and painted a heart shape by free hand. The song used here is \emph{Don't Let It Break Your Heart} by \emph{Coldplay}. As can be seen from the figure, the color of the heart changes at each time instant according to the volume of the song. A video demonstration is available at~\cite{demo:color2}.


